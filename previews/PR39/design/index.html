<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Design Discussion · DataSets.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">DataSets.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../reference/">API Reference</a></li><li class="is-active"><a class="tocitem" href>Design Discussion</a><ul class="internal"><li><a class="tocitem" href="#What-is-a-DataSet?"><span>What is a DataSet?</span></a></li><li><a class="tocitem" href="#Connecting-data-with-code"><span>Connecting data with code</span></a></li><li><a class="tocitem" href="#Data-Projects"><span>Data Projects</span></a></li><li><a class="tocitem" href="#Data-Registries"><span>Data Registries</span></a></li><li><a class="tocitem" href="#Data-REPL"><span>Data REPL</span></a></li><li><a class="tocitem" href="#Data-Lifecycle"><span>Data Lifecycle</span></a></li><li><a class="tocitem" href="#Data-Models"><span>Data Models</span></a></li><li class="toplevel"><a class="tocitem" href="#Interesting-related-projects"><span>Interesting related projects</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Design Discussion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Design Discussion</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaComputing/DataSets.jl/blob/master/docs/src/design.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="What-is-a-DataSet?"><a class="docs-heading-anchor" href="#What-is-a-DataSet?">What is a DataSet?</a><a id="What-is-a-DataSet?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-DataSet?" title="Permalink"></a></h2><p>In this library, a <code>DataSet</code> is lightweight declarative metadata describing &quot;any&quot; data in enough detail to store and load from it and to reflect it into the user&#39;s program.</p><p>Which types of metadata go in a DataSet declaration? The design principle here is to describe <em>what</em> and <em>where</em> the data is, but not <em>how</em> to open it. This is desirable because several modules with different design tradeoffs may open the same data.  Yet, it should be possible to share metadata between these. To sharpen the distinction of what vs how, imagine using <code>DataSet</code> metadata from a language other than Julia. If this makes no sense, perhaps it is <em>how</em> rather than <em>what</em>.</p><p>There&#39;s two primary things we need to know about data:</p><h3 id="Data-set-type-and-encoding"><a class="docs-heading-anchor" href="#Data-set-type-and-encoding">Data set type and encoding</a><a id="Data-set-type-and-encoding-1"></a><a class="docs-heading-anchor-permalink" href="#Data-set-type-and-encoding" title="Permalink"></a></h3><p>Data exists outside your program in many formats. We can reflect this into the program as a particular data structure with a particular Julia type, but there&#39;s rarely a unique mapping. Therefore, we should have some concept of <em>data set type</em> which is independent from the types used in a Julia program. Here we&#39;ll use the made up word <strong>dtype</strong> to avoid confusion with Julia&#39;s builtin <code>DataType</code>.</p><p>As an example of this non-uniqueness, consider the humble blob — a 1D array of bytes; the <em>content</em> of an operating system file. This data resource can be reflected into a Julia program in many ways:</p><ul><li>As an <code>IO</code> object; concretely <code>IOStream</code> as you&#39;d get from a call to <code>open()</code>.</li><li>As an array of bytes; concretely <code>Vector{UInt8}</code>, as you might get from a call to <code>mmap()</code>.</li><li>As a <code>String</code> as you&#39;d get from a call to <code>read(filename, String)</code>.</li><li>As a path object of some kind, for example, <code>FilePathsBase.PosixPath</code>.</li></ul><p>Which of these is most appropriate depends on context and must be expressed in the program code.</p><p>Conversely, the program may want to abstract over dtype, accessing many different dtypes through a common Julia type. For example, consider the problem of loading images files. There&#39;s hundreds of image formats in existence and it can be useful to map these into a single image data type for manipulation on the Julia side. So we could have dtype of JPEG, PNG and TIFF but on the Julia side load all these as <code>Matrix{&lt;:RGB}</code>.</p><p>Sometimes data isn&#39;t self describing enough to decode it without extra context so we may need to include information about <strong>data encoding</strong>.  A prime example of this is the <a href="https://juliadata.github.io/CSV.jl/stable/#CSV.File">many flavous of CSV</a>.</p><h3 id="Data-storage-drivers-and-resource-locations"><a class="docs-heading-anchor" href="#Data-storage-drivers-and-resource-locations">Data storage drivers and resource locations</a><a id="Data-storage-drivers-and-resource-locations-1"></a><a class="docs-heading-anchor-permalink" href="#Data-storage-drivers-and-resource-locations" title="Permalink"></a></h3><p>Data may be accessed via many different mechanisms. Each DataSet needs to specify the <em>storage driver</em> to allow for this. Some examples:</p><ul><li>The local filesystem</li><li>HTTP</li><li>A git server</li><li>Cloud storage like Amazon S3 and Google Drive</li><li>Research data management servers</li><li>Relational databases</li></ul><p>To create a connection to the storage and access data we need configuration such as</p><ul><li><em>resource location</em>, for example the path to a file on disk</li><li><em>version information</em> for drivers which support data versioning</li><li><em>caching strategy</em> for remote or changing data sources</li></ul><h3 id="Other-metadata"><a class="docs-heading-anchor" href="#Other-metadata">Other metadata</a><a id="Other-metadata-1"></a><a class="docs-heading-anchor-permalink" href="#Other-metadata" title="Permalink"></a></h3><p>There&#39;s other fields which could be included, for example</p><ul><li><em>unique identifier</em> to manage identity in settings where the same data resides on multiple storage systems</li><li>A <em>default name</em> for easy linking to the data project</li><li>A <em>description</em> containing freeform text, used to document the data and as content for search systems.</li></ul><h2 id="Connecting-data-with-code"><a class="docs-heading-anchor" href="#Connecting-data-with-code">Connecting data with code</a><a id="Connecting-data-with-code-1"></a><a class="docs-heading-anchor-permalink" href="#Connecting-data-with-code" title="Permalink"></a></h2><p>Having a truly useful layer for connecting data with code is surprisingly subtle. This is likely due to the many-to-many relationship between dtype vs DataType, as elaborated above.</p><p>On the one hand, the user&#39;s code should declare which Julia types (or type traits?) it&#39;s willing to consume. On the other hand, the data should declare which dtype it consists of. Somehow we need to arrange dispatch so that two type systems can meet.</p><h2 id="Data-Projects"><a class="docs-heading-anchor" href="#Data-Projects">Data Projects</a><a id="Data-Projects-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Projects" title="Permalink"></a></h2><p>For using multiple datasets together — for example, in a scientific project — we&#39;d like a <code>DataProject</code> type. A <code>DataProject</code> is a binding of convenient names to <code>DataSet</code>s. Perhaps it also maintains the serialized <code>DataSet</code> information as well for those datasets which are not registered. It might be stored in a Data.toml, in analogy to Project.toml.</p><p>Maintaince of the data project should occur via a data REPL.</p><h2 id="Data-Registries"><a class="docs-heading-anchor" href="#Data-Registries">Data Registries</a><a id="Data-Registries-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Registries" title="Permalink"></a></h2><p>For people who&#39;d like to share curated datasets publicly, we should have the concept of a data registry.</p><p>The normal package system could be a reasonable way to do this to start with. We have some precedent here in packages like RDatasets, VegaDatasets, GeoDatasets, etc.</p><p>The idea would be for the package to distribute the Data.toml metadata and any special purpose data loading code. Then hand this configuration over to DataSets.jl to provide a coherent and integrated interface to the data. Including lifecycle, downloading, caching, etc.</p><h2 id="Data-REPL"><a class="docs-heading-anchor" href="#Data-REPL">Data REPL</a><a id="Data-REPL-1"></a><a class="docs-heading-anchor-permalink" href="#Data-REPL" title="Permalink"></a></h2><p>We should have a data REPL!</p><p>What&#39;s it for?</p><ul><li>Manipulating the current data project</li><li>Listing available datasets in data project</li><li>Conveniently creating <code>DataSet</code>s, eg linking and unlinking existing local data into the data project</li><li>Copying/caching data between storage locations</li><li>...</li></ul><h2 id="Data-Lifecycle"><a class="docs-heading-anchor" href="#Data-Lifecycle">Data Lifecycle</a><a id="Data-Lifecycle-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Lifecycle" title="Permalink"></a></h2><p>For example, <code>open</code> and <code>close</code> verbs for data, caching, garbage collection, etc.</p><p><code>open/close</code> are important events which allow us to:</p><ul><li>Create and commit versions</li><li>Create and record provenance information</li><li>Update metadata, such as timestamps (eg for loosely coupled dataflows)</li></ul><h3 id="Versioning-and-mutability"><a class="docs-heading-anchor" href="#Versioning-and-mutability">Versioning and mutability</a><a id="Versioning-and-mutability-1"></a><a class="docs-heading-anchor-permalink" href="#Versioning-and-mutability" title="Permalink"></a></h3><p>Versions are necessarily managed by the data storage backend. For example:</p><ul><li>A dataset which is a store of configuration files in a git repo. In this case it&#39;s git which manages versions, and the repo which stores the version history.</li><li>Files on a filesystem have no versioning; the data is always the latest. And this can be a fine performance tradeoff for large or temporary data.</li></ul><p>However the <code>DataSet</code> should be able to store version constraints or track the &quot;latest&quot; data in some way. In terms of git concepts, this could be</p><ul><li>Pinning to a particular version tag</li><li>Following the master branch</li></ul><p>Versioning should be tied into the data lifecycle. Conceptually, the following code should</p><ol><li>Check that the tree is clean (if it&#39;s not, emit an error)</li><li>Create a tree data model and pass it to the user as <code>git_tree</code></li><li>Commit a new version using the changes made to <code>git_tree</code>.</li></ol><pre><code class="language-julia">open(dataset(&quot;some_git_tree&quot;), write=true) do git_tree
    # write or modify files in `git_tree`
    open(joinpath(git_tree, &quot;some_blob.txt&quot;), write=true) do io
        write(io, &quot;hi&quot;)
    end
end</code></pre><p>There&#39;s at least two quite different use patterns for versioning:</p><ul><li>Batch update: the entire dataset is rewritten. A bit like <code>open(filename, write=true, read=false)</code>. Your classic batch-mode application would function in this mode. You&#39;d also want this when applying updates to the algorithm.</li><li>Incremental update: some data is incrementally added or removed from the dataset. A bit like <code>open(filename, read=true, write=true)</code>. You&#39;d want to use this pattern to support differential dataflow: The upstream input dataset(s) have a diff applied; the dataflow system infers how this propagates, with the resulting patch applied to the output datasets.</li></ul><h3 id="Provenance:-What-is-this-data?-What-was-I-thinking?"><a class="docs-heading-anchor" href="#Provenance:-What-is-this-data?-What-was-I-thinking?">Provenance: What is this data? What was I thinking?</a><a id="Provenance:-What-is-this-data?-What-was-I-thinking?-1"></a><a class="docs-heading-anchor-permalink" href="#Provenance:-What-is-this-data?-What-was-I-thinking?" title="Permalink"></a></h3><p>Working with historical data can be confusing and error prone because the origin of that data may look like this:</p><p><img src="https://imgs.xkcd.com/comics/machine_learning.png" alt="[xkcd 1838](https://xkcd.com/1838)"/></p><p>The solution is to systematically record how data came to be, including input parameters and code version. This <em>data provenance</em> information comes from your activity as encoded in a possibly-interactive program, but must be stored alongside the data.</p><p>A full metadata system for data provenance is out of scope for DataSets.jl — it&#39;s a big project in its own right. But I think we should arrange the data lifecycle so that provenance can be hooked in easily by providing:</p><ul><li><em>Data lifecycle events</em> which can be used to trigger the generation and storage of provenance metadata.</li><li>A standard entry point to user code, which makes output datasets aware of input datasets.</li></ul><p>Some interesting links about provenance metadata:</p><ul><li>Watch this talk: <em>Intro to PROV</em> by Nicholas Car: https://www.youtube.com/watch?v=elPcKqWoOPg</li><li>The PROV primer: https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/#introduction</li><li>https://www.ands.org.au/working-with-data/publishing-and-reusing-data/data-provenance</li></ul><h2 id="Data-Models"><a class="docs-heading-anchor" href="#Data-Models">Data Models</a><a id="Data-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Models" title="Permalink"></a></h2><p>The Data Model is the abstraction which the dataset user interacts with. In general this can be provided by some arbitrary Julia code from an arbitrary module. We&#39;ll need a way to map the <code>DataSet</code> into the code which exposes the data model.</p><p>Examples, including some example storage formats which the data model might overlay</p><ul><li>Path-indexed tree-like data (Filesystem, Git, S3, Zip, HDF5)</li><li>Arrays (raw, HDF5+path, .npy, many image formats, geospatial rasters on WMTS)</li><li>Blobs (the unstructured vector of bytes)</li><li>Tables (csv, tsv, parquet)</li><li>Julia objects (JLD / JLD2 / <code>serialize</code> output)</li></ul><h3 id="Distributed-and-incremental-processing"><a class="docs-heading-anchor" href="#Distributed-and-incremental-processing">Distributed and incremental processing</a><a id="Distributed-and-incremental-processing-1"></a><a class="docs-heading-anchor-permalink" href="#Distributed-and-incremental-processing" title="Permalink"></a></h3><p>For distributed or incremental processing of large data, it <strong>must be possible to load data lazily and in parallel</strong>: no single node in the computation should need the whole dataset to be locally accessible.</p><p>Not every data model can support efficient parallel processing. But for those that do it seems that the following concepts are important:</p><ul><li><em>keys</em> - the user works in terms of keys, eg, the indices of an array, the elements of a set, etc.</li><li><em>indices</em> - allow data to be looked up via the keys, quickly.</li><li><em>partitions</em> - large datasets must be partitioned across machines (distributed processing) or time (incremental processing with lazy loading).  The user may not want to know about this but the scheduler does.</li></ul><p>To be clear, DataSets largely doesn&#39;t provide these things itself — these are up to implementations of particular data models. But the data lifecycle should be designed to efficiently support distributed computation.</p><h3 id="Tree-indexed-data"><a class="docs-heading-anchor" href="#Tree-indexed-data">Tree-indexed data</a><a id="Tree-indexed-data-1"></a><a class="docs-heading-anchor-permalink" href="#Tree-indexed-data" title="Permalink"></a></h3><p>This is one particular data model which I&#39;ve tackle this as a first use case, as a &quot;hieracical tree of data&quot; is so common. Examples are</p><ul><li>The filesystem - See <code>DataSets.FileTree</code></li><li>git - See <code>DataSets.GitTree</code></li><li>Zip files - See <code>ZipFileTree</code></li><li>S3</li><li>HDF5</li></ul><p>But we don&#39;t have a well-defined path tree abstraction which already exists! So I&#39;ve been prototyping some things in this package. (See also FileTrees.jl which is a new and very recent package tackling similar things.)</p><h4 id="Paths-and-Roots"><a class="docs-heading-anchor" href="#Paths-and-Roots">Paths and Roots</a><a id="Paths-and-Roots-1"></a><a class="docs-heading-anchor-permalink" href="#Paths-and-Roots" title="Permalink"></a></h4><p>What is a <strong>tree root</strong> object? It&#39;s a location for a data resource, including enough information to open that resource. It&#39;s the thing which handles the data lifecycle events on the whole tree.</p><p>What is a <strong>relative path</strong>, in general? It&#39;s a <em>key</em> into a heirarchical tree-structured data store. This consists of several path <em>components</em> (an array of strings)</p><h4 id="Iteration"><a class="docs-heading-anchor" href="#Iteration">Iteration</a><a id="Iteration-1"></a><a class="docs-heading-anchor-permalink" href="#Iteration" title="Permalink"></a></h4><ul><li>Fundamentally about iteration over tree nodes</li><li>Iteration over a tree yields a list of children. Children may be:<ul><li>Another tree; <code>isdir(child) == true</code></li><li>Leaf data</li></ul></li></ul><h1 id="Interesting-related-projects"><a class="docs-heading-anchor" href="#Interesting-related-projects">Interesting related projects</a><a id="Interesting-related-projects-1"></a><a class="docs-heading-anchor-permalink" href="#Interesting-related-projects" title="Permalink"></a></h1><ul><li><a href="https://julialang.github.io/Pkg.jl/v1/artifacts/">Pkg.Artifacts</a> solves the problem of downloading &quot;artifacts&quot;: immutable containers of content-addressed tree data. Designed for the needs of distributing compiled libraries as dependencies of Julia projects, but can be used for any tree-structured data.</li><li><a href="https://github.com/oxinabox/DataDeps.jl">DataDeps.jl</a> solves the data downloading problem for static remote data.</li><li><a href="https://github.com/helgee/RemoteFiles.jl">RemoteFiles.jl</a> Downloads files from the internet and keeps them updated.</li><li><a href="https://arrow.apache.org/docs/python/dataset.html">pyarrow.dataset</a> is restricted to tabular data, but seems similar in spirit to DataSets.jl.</li><li><a href="http://shashi.biz/FileTrees.jl">FileTrees.jl</a> provides tools for representing and processing tree-structured data lazily and in parallel.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../reference/">« API Reference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 28 April 2022 05:11">Thursday 28 April 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
